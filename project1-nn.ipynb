{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:17:40.121982Z",
     "iopub.status.busy": "2023-03-30T01:17:40.121507Z",
     "iopub.status.idle": "2023-03-30T01:17:41.001637Z",
     "shell.execute_reply": "2023-03-30T01:17:41.000244Z",
     "shell.execute_reply.started": "2023-03-30T01:17:40.121942Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:17:52.635173Z",
     "iopub.status.busy": "2023-03-30T01:17:52.634653Z",
     "iopub.status.idle": "2023-03-30T01:17:54.100816Z",
     "shell.execute_reply": "2023-03-30T01:17:54.099315Z",
     "shell.execute_reply.started": "2023-03-30T01:17:52.635125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440000, 190)\n",
      "(458913, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(458913, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\aniqa\\Desktop\\Courses\\Semester_2\\Machine_Learning\\Project 1\\Code\\train_data.csv\", nrows=1440000)\n",
    "train_labels_data = pd.read_csv(r\"C:\\Users\\aniqa\\Desktop\\Courses\\Semester_2\\Machine_Learning\\Project 1\\Code\\train_labels.csv\")\n",
    "\n",
    "#data = train_data.sample(frac=1)\n",
    "#train_data_sample = data.groupby('customer_ID',as_index=False).first()\n",
    "\n",
    "#print(data2)\n",
    "print(train_data.shape)\n",
    "print(train_labels_data.shape)\n",
    "train_data.shape\n",
    "train_labels_data.shape\n",
    "#print(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:17:56.871068Z",
     "iopub.status.busy": "2023-03-30T01:17:56.869534Z",
     "iopub.status.idle": "2023-03-30T01:17:56.907310Z",
     "shell.execute_reply": "2023-03-30T01:17:56.905907Z",
     "shell.execute_reply.started": "2023-03-30T01:17:56.870991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                customer_ID         S_2  \\\n",
      "0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09   \n",
      "1        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07   \n",
      "2        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28   \n",
      "3        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13   \n",
      "4        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16   \n",
      "...                                                    ...         ...   \n",
      "1439995  425d5532a25f20815166956bc7fb3a49928f4c49517e1c...  2017-06-29   \n",
      "1439996  425d5532a25f20815166956bc7fb3a49928f4c49517e1c...  2017-07-29   \n",
      "1439997  425d5532a25f20815166956bc7fb3a49928f4c49517e1c...  2017-08-30   \n",
      "1439998  425d5532a25f20815166956bc7fb3a49928f4c49517e1c...  2017-09-29   \n",
      "1439999  425d5532a25f20815166956bc7fb3a49928f4c49517e1c...  2017-10-30   \n",
      "\n",
      "              P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
      "0        0.938469  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771   \n",
      "1        0.936665  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798   \n",
      "2        0.954180  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598   \n",
      "3        0.960384  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685   \n",
      "4        0.947248  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "1439995  0.874078  0.004086  0.008672  0.815791  0.005246       NaN  0.008112   \n",
      "1439996  0.872043  0.007395  0.001348  0.819464  0.004784       NaN  0.009488   \n",
      "1439997  0.867252  0.008150  0.008059  0.818707  0.007366       NaN  0.005170   \n",
      "1439998  0.934603  0.002312  0.006102  0.816108  0.003532       NaN  0.000250   \n",
      "1439999  0.938461  0.005231  0.000666  0.810569  0.007312       NaN  0.004932   \n",
      "\n",
      "              B_3  ...  D_136  D_137  D_138     D_139     D_140     D_141  \\\n",
      "0        0.004709  ...    NaN    NaN    NaN  0.002427  0.003706  0.003818   \n",
      "1        0.002714  ...    NaN    NaN    NaN  0.003954  0.003167  0.005032   \n",
      "2        0.009423  ...    NaN    NaN    NaN  0.003269  0.007329  0.000427   \n",
      "3        0.005531  ...    NaN    NaN    NaN  0.006117  0.004516  0.003200   \n",
      "4        0.009312  ...    NaN    NaN    NaN  0.003671  0.004946  0.008889   \n",
      "...           ...  ...    ...    ...    ...       ...       ...       ...   \n",
      "1439995  0.006125  ...    NaN    NaN    NaN  0.002196  0.006976  0.004546   \n",
      "1439996  0.008950  ...    NaN    NaN    NaN  0.002335  0.005112  0.003713   \n",
      "1439997  0.000103  ...    NaN    NaN    NaN  0.005987  0.008728  0.004927   \n",
      "1439998  0.000844  ...    NaN    NaN    NaN  0.006903  0.004097  0.009254   \n",
      "1439999  0.002325  ...    NaN    NaN    NaN  0.008898  0.006947  0.008566   \n",
      "\n",
      "         D_142     D_143     D_144     D_145  \n",
      "0          NaN  0.000569  0.000610  0.002674  \n",
      "1          NaN  0.009576  0.005492  0.009217  \n",
      "2          NaN  0.003429  0.006986  0.002603  \n",
      "3          NaN  0.008419  0.006527  0.009600  \n",
      "4          NaN  0.001670  0.008126  0.009827  \n",
      "...        ...       ...       ...       ...  \n",
      "1439995    NaN  0.009514  0.002603  0.009218  \n",
      "1439996    NaN  0.000811  0.008883  0.001153  \n",
      "1439997    NaN  0.007416  0.006252  0.002668  \n",
      "1439998    NaN  0.005879  0.002002  0.005971  \n",
      "1439999    NaN  0.001507  0.001307  0.009375  \n",
      "\n",
      "[1440000 rows x 190 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:18:16.520157Z",
     "iopub.status.busy": "2023-03-30T01:18:16.519674Z",
     "iopub.status.idle": "2023-03-30T01:18:16.576701Z",
     "shell.execute_reply": "2023-03-30T01:18:16.574722Z",
     "shell.execute_reply.started": "2023-03-30T01:18:16.520116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1439995</th>\n",
       "      <td>425d5532a25f20815166956bc7fb3a49928f4c49517e1c...</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>0.874078</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>0.815791</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.009218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439996</th>\n",
       "      <td>425d5532a25f20815166956bc7fb3a49928f4c49517e1c...</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>0.872043</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.819464</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439997</th>\n",
       "      <td>425d5532a25f20815166956bc7fb3a49928f4c49517e1c...</td>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>0.867252</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.818707</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.002668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439998</th>\n",
       "      <td>425d5532a25f20815166956bc7fb3a49928f4c49517e1c...</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>0.934603</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>0.816108</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.005971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439999</th>\n",
       "      <td>425d5532a25f20815166956bc7fb3a49928f4c49517e1c...</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>0.938461</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.810569</td>\n",
       "      <td>0.007312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008898</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.009375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_ID        S_2  \\\n",
       "1439995  425d5532a25f20815166956bc7fb3a49928f4c49517e1c... 2017-06-29   \n",
       "1439996  425d5532a25f20815166956bc7fb3a49928f4c49517e1c... 2017-07-29   \n",
       "1439997  425d5532a25f20815166956bc7fb3a49928f4c49517e1c... 2017-08-30   \n",
       "1439998  425d5532a25f20815166956bc7fb3a49928f4c49517e1c... 2017-09-29   \n",
       "1439999  425d5532a25f20815166956bc7fb3a49928f4c49517e1c... 2017-10-30   \n",
       "\n",
       "              P_2      D_39       B_1       B_2       R_1  S_3      D_41  \\\n",
       "1439995  0.874078  0.004086  0.008672  0.815791  0.005246  NaN  0.008112   \n",
       "1439996  0.872043  0.007395  0.001348  0.819464  0.004784  NaN  0.009488   \n",
       "1439997  0.867252  0.008150  0.008059  0.818707  0.007366  NaN  0.005170   \n",
       "1439998  0.934603  0.002312  0.006102  0.816108  0.003532  NaN  0.000250   \n",
       "1439999  0.938461  0.005231  0.000666  0.810569  0.007312  NaN  0.004932   \n",
       "\n",
       "              B_3  ...  D_136  D_137  D_138     D_139     D_140     D_141  \\\n",
       "1439995  0.006125  ...    NaN    NaN    NaN  0.002196  0.006976  0.004546   \n",
       "1439996  0.008950  ...    NaN    NaN    NaN  0.002335  0.005112  0.003713   \n",
       "1439997  0.000103  ...    NaN    NaN    NaN  0.005987  0.008728  0.004927   \n",
       "1439998  0.000844  ...    NaN    NaN    NaN  0.006903  0.004097  0.009254   \n",
       "1439999  0.002325  ...    NaN    NaN    NaN  0.008898  0.006947  0.008566   \n",
       "\n",
       "         D_142     D_143     D_144     D_145  \n",
       "1439995    NaN  0.009514  0.002603  0.009218  \n",
       "1439996    NaN  0.000811  0.008883  0.001153  \n",
       "1439997    NaN  0.007416  0.006252  0.002668  \n",
       "1439998    NaN  0.005879  0.002002  0.005971  \n",
       "1439999    NaN  0.001507  0.001307  0.009375  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['S_2'] = pd.to_datetime(train_data['S_2'])\n",
    "#data = data.groupby('customer_ID')\n",
    "train_data.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:18:21.965272Z",
     "iopub.status.busy": "2023-03-30T01:18:21.963982Z",
     "iopub.status.idle": "2023-03-30T01:18:21.972987Z",
     "shell.execute_reply": "2023-03-30T01:18:21.971237Z",
     "shell.execute_reply.started": "2023-03-30T01:18:21.965215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425d5532a25f20815166956bc7fb3a49928f4c49517e1c59f9843f13a8aad690\n"
     ]
    }
   ],
   "source": [
    "last_customer_id = train_data['customer_ID'].iloc[-1]\n",
    "print(last_customer_id)\n",
    "\n",
    "#data2 = train_data_sample[train_data_sample['customer_ID'] != '425d5532a25f20815166956bc7fb3a49928f4c49517e1c59f9843f13a8aad690']\n",
    "#print(data2.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:18:25.720252Z",
     "iopub.status.busy": "2023-03-30T01:18:25.719770Z",
     "iopub.status.idle": "2023-03-30T01:18:25.753164Z",
     "shell.execute_reply": "2023-03-30T01:18:25.751627Z",
     "shell.execute_reply.started": "2023-03-30T01:18:25.720209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.tail of                                                customer_ID        S_2  \\\n",
      "0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-03-09   \n",
      "1        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-04-07   \n",
      "2        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-05-28   \n",
      "3        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-06-13   \n",
      "4        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-07-16   \n",
      "...                                                    ...        ...   \n",
      "1439987  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2017-11-02   \n",
      "1439988  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2017-12-22   \n",
      "1439989  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2018-01-18   \n",
      "1439990  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2018-02-18   \n",
      "1439991  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2018-03-12   \n",
      "\n",
      "              P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
      "0        0.938469  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771   \n",
      "1        0.936665  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798   \n",
      "2        0.954180  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598   \n",
      "3        0.960384  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685   \n",
      "4        0.947248  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "1439987  0.849775  0.005104  0.010486  1.003217  0.003182  0.150330  0.000860   \n",
      "1439988  0.851198  0.004490  0.014734  1.006323  0.000302  0.138393  0.009412   \n",
      "1439989  0.805918  0.298139  0.014284  1.005040  0.006340  0.135215  0.001861   \n",
      "1439990  0.801010  0.385806  0.019405  1.008273  0.005823  0.132571  0.001117   \n",
      "1439991  0.835906  0.119807  0.016720  1.005346  0.004553  0.123686  0.000462   \n",
      "\n",
      "              B_3  ...  D_136  D_137  D_138     D_139     D_140     D_141  \\\n",
      "0        0.004709  ...    NaN    NaN    NaN  0.002427  0.003706  0.003818   \n",
      "1        0.002714  ...    NaN    NaN    NaN  0.003954  0.003167  0.005032   \n",
      "2        0.009423  ...    NaN    NaN    NaN  0.003269  0.007329  0.000427   \n",
      "3        0.005531  ...    NaN    NaN    NaN  0.006117  0.004516  0.003200   \n",
      "4        0.009312  ...    NaN    NaN    NaN  0.003671  0.004946  0.008889   \n",
      "...           ...  ...    ...    ...    ...       ...       ...       ...   \n",
      "1439987  0.003142  ...    NaN    NaN    NaN  1.007058  0.004694  0.998317   \n",
      "1439988  0.004341  ...    NaN    NaN    NaN  1.003214  0.003488  1.000071   \n",
      "1439989  0.002924  ...    NaN    NaN    NaN  1.008916  0.001093  0.994132   \n",
      "1439990  0.007921  ...    NaN    NaN    NaN  1.000475  0.001057  1.001628   \n",
      "1439991  0.003511  ...    NaN    NaN    NaN  1.009225  0.004313  1.001021   \n",
      "\n",
      "            D_142     D_143     D_144     D_145  \n",
      "0             NaN  0.000569  0.000610  0.002674  \n",
      "1             NaN  0.009576  0.005492  0.009217  \n",
      "2             NaN  0.003429  0.006986  0.002603  \n",
      "3             NaN  0.008419  0.006527  0.009600  \n",
      "4             NaN  0.001670  0.008126  0.009827  \n",
      "...           ...       ...       ...       ...  \n",
      "1439987  0.636693  1.007044  0.343181  0.097249  \n",
      "1439988  0.648364  1.006816  0.343017  0.098441  \n",
      "1439989  0.643986  1.005871  0.341721  0.094478  \n",
      "1439990  0.654863  1.002669  0.334294  0.091886  \n",
      "1439991  0.650735  1.000669  0.340694  0.094627  \n",
      "\n",
      "[1439992 rows x 190 columns]>\n"
     ]
    }
   ],
   "source": [
    "data2 = train_data[train_data['customer_ID'] != last_customer_id]\n",
    "print(data2.tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:18:29.139640Z",
     "iopub.status.busy": "2023-03-30T01:18:29.138971Z",
     "iopub.status.idle": "2023-03-30T01:18:29.149729Z",
     "shell.execute_reply": "2023-03-30T01:18:29.148161Z",
     "shell.execute_reply.started": "2023-03-30T01:18:29.139578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439992, 190)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:18:31.022633Z",
     "iopub.status.busy": "2023-03-30T01:18:31.022130Z",
     "iopub.status.idle": "2023-03-30T01:18:31.278592Z",
     "shell.execute_reply": "2023-03-30T01:18:31.277179Z",
     "shell.execute_reply.started": "2023-03-30T01:18:31.022584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1439992, 191)\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(data2, train_labels_data, on='customer_ID').dropna(subset=['target'])\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:18:36.959273Z",
     "iopub.status.busy": "2023-03-30T01:18:36.958792Z",
     "iopub.status.idle": "2023-03-30T01:18:39.411662Z",
     "shell.execute_reply": "2023-03-30T01:18:39.410403Z",
     "shell.execute_reply.started": "2023-03-30T01:18:36.959227Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_data.to_csv(r\"C:\\Users\\aniqa\\Desktop\\Courses\\Semester_2\\Machine_Learning\\Project 1\\Code\\merged_data_nn.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:04.723731Z",
     "iopub.status.busy": "2023-03-30T01:19:04.723246Z",
     "iopub.status.idle": "2023-03-30T01:19:04.737427Z",
     "shell.execute_reply": "2023-03-30T01:19:04.735756Z",
     "shell.execute_reply.started": "2023-03-30T01:19:04.723687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   label            type\n",
      "customer_ID  customer_ID          object\n",
      "S_2                  S_2  datetime64[ns]\n",
      "P_2                  P_2         float64\n",
      "D_39                D_39         float64\n",
      "B_1                  B_1         float64\n",
      "...                  ...             ...\n",
      "D_142              D_142         float64\n",
      "D_143              D_143         float64\n",
      "D_144              D_144         float64\n",
      "D_145              D_145         float64\n",
      "target            target           int64\n",
      "\n",
      "[191 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data_types = merged_data.dtypes\n",
    "data_types = pd.DataFrame({\"label\": merged_data.columns,\"type\": data_types})\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:07.299730Z",
     "iopub.status.busy": "2023-03-30T01:19:07.299230Z",
     "iopub.status.idle": "2023-03-30T01:19:07.310168Z",
     "shell.execute_reply": "2023-03-30T01:19:07.308468Z",
     "shell.execute_reply.started": "2023-03-30T01:19:07.299683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   label    type\n",
      "customer_ID  customer_ID  object\n",
      "D_63                D_63  object\n",
      "D_64                D_64  object\n"
     ]
    }
   ],
   "source": [
    "categorical_variables = data_types.loc[data_types['type']=='object']\n",
    "print(categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:10.038193Z",
     "iopub.status.busy": "2023-03-30T01:19:10.037711Z",
     "iopub.status.idle": "2023-03-30T01:19:10.047882Z",
     "shell.execute_reply": "2023-03-30T01:19:10.046171Z",
     "shell.execute_reply.started": "2023-03-30T01:19:10.038154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label    type\n",
      "D_63  D_63  object\n",
      "D_64  D_64  object\n"
     ]
    }
   ],
   "source": [
    "categorical_variables = categorical_variables.iloc[1:]\n",
    "print(categorical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:12.223126Z",
     "iopub.status.busy": "2023-03-30T01:19:12.222659Z",
     "iopub.status.idle": "2023-03-30T01:19:12.230943Z",
     "shell.execute_reply": "2023-03-30T01:19:12.229252Z",
     "shell.execute_reply.started": "2023-03-30T01:19:12.223085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D_63', 'D_64']\n"
     ]
    }
   ],
   "source": [
    "cat_list = categorical_variables.iloc[:, 0].tolist()\n",
    "print(cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:14.425999Z",
     "iopub.status.busy": "2023-03-30T01:19:14.425295Z",
     "iopub.status.idle": "2023-03-30T01:19:14.487124Z",
     "shell.execute_reply": "2023-03-30T01:19:14.485078Z",
     "shell.execute_reply.started": "2023-03-30T01:19:14.425910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               customer_ID        S_2  \\\n",
      "0        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-03-09   \n",
      "1        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-04-07   \n",
      "2        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-05-28   \n",
      "3        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-06-13   \n",
      "4        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-07-16   \n",
      "...                                                    ...        ...   \n",
      "1439987  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2017-11-02   \n",
      "1439988  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2017-12-22   \n",
      "1439989  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2018-01-18   \n",
      "1439990  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2018-02-18   \n",
      "1439991  425d3742a1fd67755c431a132257d18e81234fc36985cd... 2018-03-12   \n",
      "\n",
      "              P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
      "0        0.938469  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771   \n",
      "1        0.936665  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798   \n",
      "2        0.954180  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598   \n",
      "3        0.960384  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685   \n",
      "4        0.947248  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "1439987  0.849775  0.005104  0.010486  1.003217  0.003182  0.150330  0.000860   \n",
      "1439988  0.851198  0.004490  0.014734  1.006323  0.000302  0.138393  0.009412   \n",
      "1439989  0.805918  0.298139  0.014284  1.005040  0.006340  0.135215  0.001861   \n",
      "1439990  0.801010  0.385806  0.019405  1.008273  0.005823  0.132571  0.001117   \n",
      "1439991  0.835906  0.119807  0.016720  1.005346  0.004553  0.123686  0.000462   \n",
      "\n",
      "              B_3  ...  D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_64_-1  \\\n",
      "0        0.004709  ...      0.0      1.0      0.0      0.0      0.0      0.0   \n",
      "1        0.002714  ...      0.0      1.0      0.0      0.0      0.0      0.0   \n",
      "2        0.009423  ...      0.0      1.0      0.0      0.0      0.0      0.0   \n",
      "3        0.005531  ...      0.0      1.0      0.0      0.0      0.0      0.0   \n",
      "4        0.009312  ...      0.0      1.0      0.0      0.0      0.0      0.0   \n",
      "...           ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "1439987  0.003142  ...      1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1439988  0.004341  ...      1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1439989  0.002924  ...      1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1439990  0.007921  ...      1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1439991  0.003511  ...      1.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "         D_64_O  D_64_R  D_64_U  D_64_nan  \n",
      "0           1.0     0.0     0.0       0.0  \n",
      "1           1.0     0.0     0.0       0.0  \n",
      "2           1.0     0.0     0.0       0.0  \n",
      "3           1.0     0.0     0.0       0.0  \n",
      "4           1.0     0.0     0.0       0.0  \n",
      "...         ...     ...     ...       ...  \n",
      "1439987     0.0     0.0     1.0       0.0  \n",
      "1439988     0.0     0.0     1.0       0.0  \n",
      "1439989     0.0     0.0     1.0       0.0  \n",
      "1439990     0.0     0.0     1.0       0.0  \n",
      "1439991     0.0     0.0     1.0       0.0  \n",
      "\n",
      "[1439992 rows x 202 columns]\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder(handle_unknown = 'ignore')\n",
    "one_hot.fit(merged_data[cat_list])\n",
    "merged_data_encoded = pd.DataFrame(one_hot.transform(merged_data[cat_list]).toarray(),columns = one_hot.get_feature_names_out(cat_list))\n",
    "merged_data = pd.concat([merged_data.reset_index(drop = True), merged_data_encoded.reset_index(drop=True)],axis = 1)\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:26:28.737441Z",
     "iopub.status.busy": "2023-03-30T01:26:28.736997Z",
     "iopub.status.idle": "2023-03-30T01:26:28.746501Z",
     "shell.execute_reply": "2023-03-30T01:26:28.745278Z",
     "shell.execute_reply.started": "2023-03-30T01:26:28.737402Z"
    }
   },
   "outputs": [],
   "source": [
    "#Missing value imputation\n",
    "merged_data.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:17.653240Z",
     "iopub.status.busy": "2023-03-30T01:19:17.652644Z",
     "iopub.status.idle": "2023-03-30T01:19:17.663967Z",
     "shell.execute_reply": "2023-03-30T01:19:17.662133Z",
     "shell.execute_reply.started": "2023-03-30T01:19:17.653185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-01 00:00:00\n",
      "2018-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(merged_data['S_2'].min())\n",
    "print(merged_data['S_2'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:19.195567Z",
     "iopub.status.busy": "2023-03-30T01:19:19.194757Z",
     "iopub.status.idle": "2023-03-30T01:19:19.228060Z",
     "shell.execute_reply": "2023-03-30T01:19:19.226937Z",
     "shell.execute_reply.started": "2023-03-30T01:19:19.195512Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = merged_data[(merged_data['S_2']>='2017-05-01') & (merged_data[\"S_2\"] <= '2018-01-31')]\n",
    "test1_data = merged_data[(merged_data['S_2']>='2017-03-01') & (merged_data['S_2'] <= '2017-04-30')]\n",
    "test2_data = merged_data[(merged_data['S_2']>='2018-02-01') & (merged_data['S_2'] <= '2018-03-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:21.966943Z",
     "iopub.status.busy": "2023-03-30T01:19:21.966466Z",
     "iopub.status.idle": "2023-03-30T01:19:21.981706Z",
     "shell.execute_reply": "2023-03-30T01:19:21.979285Z",
     "shell.execute_reply.started": "2023-03-30T01:19:21.966881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-01 00:00:00\n",
      "2018-01-31 00:00:00\n",
      "2017-03-01 00:00:00\n",
      "2017-04-30 00:00:00\n",
      "2018-02-01 00:00:00\n",
      "2018-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train_data['S_2'].min())\n",
    "print(train_data['S_2'].max())\n",
    "print(test1_data['S_2'].min())\n",
    "print(test1_data['S_2'].max())\n",
    "print(test2_data['S_2'].min())\n",
    "print(test2_data['S_2'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature importance data saved from XGBoost model. We will only run normalization and outlier treatment on these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T20:41:39.610430Z",
     "iopub.status.busy": "2023-03-29T20:41:39.610006Z",
     "iopub.status.idle": "2023-03-29T20:41:39.620088Z",
     "shell.execute_reply": "2023-03-29T20:41:39.618272Z",
     "shell.execute_reply.started": "2023-03-29T20:41:39.610399Z"
    }
   },
   "outputs": [],
   "source": [
    "merged_importance_df=pd.read_csv(r\"C:\\Users\\aniqa\\Desktop\\Courses\\Semester_2\\Machine_Learning\\Project 1\\Code\\merged_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T20:41:42.775509Z",
     "iopub.status.busy": "2023-03-29T20:41:42.775059Z",
     "iopub.status.idle": "2023-03-29T20:41:42.786363Z",
     "shell.execute_reply": "2023-03-29T20:41:42.784699Z",
     "shell.execute_reply.started": "2023-03-29T20:41:42.775471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask for features with importance greater than 0.5% in either column\n",
    "mask = (merged_importance_df['importance_1'] > 0.005) | (merged_importance_df['importance_2'] > 0.005)\n",
    "\n",
    "# Get the feature names where the mask is True\n",
    "important_features = merged_importance_df.loc[mask, 'feature_name'].tolist()\n",
    "print(len(important_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:24.204705Z",
     "iopub.status.busy": "2023-03-30T01:19:24.204089Z",
     "iopub.status.idle": "2023-03-30T01:19:24.216682Z",
     "shell.execute_reply": "2023-03-30T01:19:24.215084Z",
     "shell.execute_reply.started": "2023-03-30T01:19:24.204656Z"
    }
   },
   "outputs": [],
   "source": [
    "target_col = 'target'\n",
    "drop_cols = ['customer_ID','S_2', 'D_63','D_64',target_col]\n",
    "\n",
    "X_train = train_data.drop(columns = drop_cols)\n",
    "X_train = X_train[important_features]\n",
    "Y_train = train_data[target_col]\n",
    "\n",
    "X_test1 = test1_data.drop(columns = drop_cols)\n",
    "X_test1 = X_test1[important_features]\n",
    "Y_test1 = test1_data[target_col]\n",
    "\n",
    "X_test2 = test2_data.drop(columns = drop_cols)\n",
    "X_test2 = X_test2[important_features]\n",
    "Y_test2 = test2_data[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:26.923008Z",
     "iopub.status.busy": "2023-03-30T01:19:26.922534Z",
     "iopub.status.idle": "2023-03-30T01:19:26.932503Z",
     "shell.execute_reply": "2023-03-30T01:19:26.930020Z",
     "shell.execute_reply.started": "2023-03-30T01:19:26.922965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(995264, 41)\n",
      "249910\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:29.217387Z",
     "iopub.status.busy": "2023-03-30T01:19:29.215505Z",
     "iopub.status.idle": "2023-03-30T01:19:29.265140Z",
     "shell.execute_reply": "2023-03-30T01:19:29.263340Z",
     "shell.execute_reply.started": "2023-03-30T01:19:29.217318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:33.971415Z",
     "iopub.status.busy": "2023-03-30T01:19:33.970172Z",
     "iopub.status.idle": "2023-03-30T01:19:33.997985Z",
     "shell.execute_reply": "2023-03-30T01:19:33.996288Z",
     "shell.execute_reply.started": "2023-03-30T01:19:33.971352Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_normalized = sc.transform(X_train)\n",
    "X_test1_normalized = sc.transform(X_test1)\n",
    "X_test2_normalized = sc.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:19:36.524372Z",
     "iopub.status.busy": "2023-03-30T01:19:36.523819Z",
     "iopub.status.idle": "2023-03-30T01:19:36.536807Z",
     "shell.execute_reply": "2023-03-30T01:19:36.534749Z",
     "shell.execute_reply.started": "2023-03-30T01:19:36.524315Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_normalized = pd.DataFrame(X_train_normalized, columns=X_train.columns)\n",
    "X_test1_normalized = pd.DataFrame(X_test1_normalized, columns=X_test1.columns)\n",
    "X_test2_normalized = pd.DataFrame(X_test2_normalized, columns=X_test2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:26:20.043013Z",
     "iopub.status.busy": "2023-03-30T01:26:20.042521Z",
     "iopub.status.idle": "2023-03-30T01:26:22.138482Z",
     "shell.execute_reply": "2023-03-30T01:26:22.136871Z",
     "shell.execute_reply.started": "2023-03-30T01:26:20.042969Z"
    }
   },
   "outputs": [],
   "source": [
    "#Outlier Treatment for train sample\n",
    "X_train_normalized.describe(percentiles=[0.01, 0.99]).transpose()\n",
    "\n",
    "for col in X_train_normalized.columns:\n",
    "    # calculate the 1% and 99% quantiles for the column\n",
    "    min_val = X_train_normalized[col].quantile(0.01)\n",
    "    max_val = X_train_normalized[col].quantile(0.99)\n",
    "    \n",
    "    #replace any values outside of the range with the corresponding minimum or maximum value\n",
    "    X_train_normalized[col] = X_train_normalized[col].apply(lambda x: min_val if x < min_val else max_val if x > max_val else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:26:20.043013Z",
     "iopub.status.busy": "2023-03-30T01:26:20.042521Z",
     "iopub.status.idle": "2023-03-30T01:26:22.138482Z",
     "shell.execute_reply": "2023-03-30T01:26:22.136871Z",
     "shell.execute_reply.started": "2023-03-30T01:26:20.042969Z"
    }
   },
   "outputs": [],
   "source": [
    "#Outlier Treatment for test sample 1\n",
    "X_test1_normalized.describe(percentiles=[0.01, 0.99]).transpose()\n",
    "\n",
    "for col in X_train_normalized.columns:\n",
    "    # calculate the 1% and 99% quantiles for the column\n",
    "    min_val = X_test1_normalized[col].quantile(0.01)\n",
    "    max_val = X_test1_normalized[col].quantile(0.99)\n",
    "    \n",
    "    #replace any values outside of the range with the corresponding minimum or maximum value\n",
    "    X_test1_normalized[col] = X_test1_normalized[col].apply(lambda x: min_val if x < min_val else max_val if x > max_val else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T01:26:20.043013Z",
     "iopub.status.busy": "2023-03-30T01:26:20.042521Z",
     "iopub.status.idle": "2023-03-30T01:26:22.138482Z",
     "shell.execute_reply": "2023-03-30T01:26:22.136871Z",
     "shell.execute_reply.started": "2023-03-30T01:26:20.042969Z"
    }
   },
   "outputs": [],
   "source": [
    "#Outlier Treatment for test sample 2\n",
    "X_test2_normalized.describe(percentiles=[0.01, 0.99]).transpose()\n",
    "\n",
    "for col in X_train_normalized.columns:\n",
    "    # calculate the 1% and 99% quantiles for the column\n",
    "    min_val = X_test2_normalized[col].quantile(0.01)\n",
    "    max_val = X_test2_normalized[col].quantile(0.99)\n",
    "    \n",
    "    #replace any values outside of the range with the corresponding minimum or maximum value\n",
    "    X_test2_normalized[col] = X_test2_normalized[col].apply(lambda x: min_val if x < min_val else max_val if x > max_val else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T22:21:49.686622Z",
     "iopub.status.busy": "2023-03-29T22:21:49.686215Z",
     "iopub.status.idle": "2023-03-29T22:22:01.293960Z",
     "shell.execute_reply": "2023-03-29T22:22:01.291201Z",
     "shell.execute_reply.started": "2023-03-29T22:21:49.686591Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31102/31102 [==============================] - 19s 592us/step\n",
      "6486/6486 [==============================] - 4s 604us/step\n",
      "7413/7413 [==============================] - 5s 608us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.931983\n",
      "AUC Test 1             0.916454\n",
      "AUC Test 2              0.95054\n",
      "Name: 0, dtype: object\n",
      "31102/31102 [==============================] - 19s 599us/step\n",
      "6486/6486 [==============================] - 4s 600us/step\n",
      "7413/7413 [==============================] - 4s 605us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.930433\n",
      "AUC Test 1             0.914649\n",
      "AUC Test 2             0.949792\n",
      "Name: 1, dtype: object\n",
      "31102/31102 [==============================] - 19s 595us/step\n",
      "6486/6486 [==============================] - 4s 600us/step\n",
      "7413/7413 [==============================] - 4s 596us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train              0.932695\n",
      "AUC Test 1              0.91744\n",
      "AUC Test 2             0.950892\n",
      "Name: 2, dtype: object\n",
      "31102/31102 [==============================] - 19s 605us/step\n",
      "6486/6486 [==============================] - 4s 595us/step\n",
      "7413/7413 [==============================] - 4s 601us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train              0.931084\n",
      "AUC Test 1             0.915032\n",
      "AUC Test 2             0.949884\n",
      "Name: 3, dtype: object\n",
      "31102/31102 [==============================] - 19s 595us/step\n",
      "6486/6486 [==============================] - 4s 597us/step\n",
      "7413/7413 [==============================] - 4s 598us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.932555\n",
      "AUC Test 1             0.917179\n",
      "AUC Test 2             0.950643\n",
      "Name: 4, dtype: object\n",
      "31102/31102 [==============================] - 19s 598us/step\n",
      "6486/6486 [==============================] - 4s 602us/step\n",
      "7413/7413 [==============================] - 4s 598us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.930443\n",
      "AUC Test 1             0.914472\n",
      "AUC Test 2              0.94965\n",
      "Name: 5, dtype: object\n",
      "31102/31102 [==============================] - 19s 604us/step\n",
      "6486/6486 [==============================] - 4s 619us/step\n",
      "7413/7413 [==============================] - 5s 606us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train              0.932511\n",
      "AUC Test 1              0.91658\n",
      "AUC Test 2             0.950511\n",
      "Name: 6, dtype: object\n",
      "31102/31102 [==============================] - 18s 590us/step\n",
      "6486/6486 [==============================] - 4s 612us/step\n",
      "7413/7413 [==============================] - 5s 607us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train               0.93087\n",
      "AUC Test 1             0.914712\n",
      "AUC Test 2             0.949751\n",
      "Name: 7, dtype: object\n",
      "31102/31102 [==============================] - 18s 592us/step\n",
      "6486/6486 [==============================] - 4s 602us/step\n",
      "7413/7413 [==============================] - 4s 604us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.933244\n",
      "AUC Test 1             0.917636\n",
      "AUC Test 2             0.951272\n",
      "Name: 8, dtype: object\n",
      "31102/31102 [==============================] - 19s 607us/step\n",
      "6486/6486 [==============================] - 4s 595us/step\n",
      "7413/7413 [==============================] - 4s 600us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.931565\n",
      "AUC Test 1             0.915939\n",
      "AUC Test 2             0.950246\n",
      "Name: 9, dtype: object\n",
      "31102/31102 [==============================] - 19s 595us/step\n",
      "6486/6486 [==============================] - 4s 630us/step\n",
      "7413/7413 [==============================] - 5s 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train              0.933556\n",
      "AUC Test 1             0.918125\n",
      "AUC Test 2             0.951313\n",
      "Name: 10, dtype: object\n",
      "31102/31102 [==============================] - 18s 591us/step\n",
      "6486/6486 [==============================] - 4s 597us/step\n",
      "7413/7413 [==============================] - 4s 598us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train              0.932075\n",
      "AUC Test 1             0.916574\n",
      "AUC Test 2             0.950443\n",
      "Name: 11, dtype: object\n",
      "31102/31102 [==============================] - 19s 618us/step\n",
      "6486/6486 [==============================] - 4s 604us/step\n",
      "7413/7413 [==============================] - 5s 609us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.932905\n",
      "AUC Test 1             0.917116\n",
      "AUC Test 2              0.95093\n",
      "Name: 12, dtype: object\n",
      "31102/31102 [==============================] - 19s 600us/step\n",
      "6486/6486 [==============================] - 4s 617us/step\n",
      "7413/7413 [==============================] - 4s 604us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.930052\n",
      "AUC Test 1             0.913876\n",
      "AUC Test 2             0.948954\n",
      "Name: 13, dtype: object\n",
      "31102/31102 [==============================] - 18s 590us/step\n",
      "6486/6486 [==============================] - 4s 599us/step\n",
      "7413/7413 [==============================] - 4s 593us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train              0.932928\n",
      "AUC Test 1             0.917214\n",
      "AUC Test 2             0.951086\n",
      "Name: 14, dtype: object\n",
      "31102/31102 [==============================] - 19s 604us/step\n",
      "6486/6486 [==============================] - 4s 606us/step\n",
      "7413/7413 [==============================] - 4s 597us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          2\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train              0.931227\n",
      "AUC Test 1             0.915103\n",
      "AUC Test 2             0.949484\n",
      "Name: 15, dtype: object\n",
      "31102/31102 [==============================] - 19s 606us/step\n",
      "6486/6486 [==============================] - 4s 625us/step\n",
      "7413/7413 [==============================] - 5s 620us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.910205\n",
      "AUC Test 1             0.901175\n",
      "AUC Test 2             0.917439\n",
      "Name: 16, dtype: object\n",
      "31102/31102 [==============================] - 19s 616us/step\n",
      "6486/6486 [==============================] - 4s 617us/step\n",
      "7413/7413 [==============================] - 4s 602us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.930999\n",
      "AUC Test 1             0.915007\n",
      "AUC Test 2              0.95022\n",
      "Name: 17, dtype: object\n",
      "31102/31102 [==============================] - 20s 633us/step\n",
      "6486/6486 [==============================] - 4s 625us/step\n",
      "7413/7413 [==============================] - 5s 614us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train               0.93284\n",
      "AUC Test 1             0.917386\n",
      "AUC Test 2             0.951124\n",
      "Name: 18, dtype: object\n",
      "31102/31102 [==============================] - 19s 595us/step\n",
      "6486/6486 [==============================] - 4s 610us/step\n",
      "7413/7413 [==============================] - 5s 611us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train               0.91764\n",
      "AUC Test 1              0.89512\n",
      "AUC Test 2             0.943434\n",
      "Name: 19, dtype: object\n",
      "31102/31102 [==============================] - 19s 610us/step\n",
      "6486/6486 [==============================] - 4s 639us/step\n",
      "7413/7413 [==============================] - 5s 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.930302\n",
      "AUC Test 1             0.914738\n",
      "AUC Test 2             0.948262\n",
      "Name: 20, dtype: object\n",
      "31102/31102 [==============================] - 20s 626us/step\n",
      "6486/6486 [==============================] - 4s 629us/step\n",
      "7413/7413 [==============================] - 5s 636us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.930509\n",
      "AUC Test 1             0.914481\n",
      "AUC Test 2             0.949472\n",
      "Name: 21, dtype: object\n",
      "31102/31102 [==============================] - 19s 609us/step\n",
      "6486/6486 [==============================] - 4s 622us/step\n",
      "7413/7413 [==============================] - 5s 621us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train               0.93258\n",
      "AUC Test 1             0.916917\n",
      "AUC Test 2             0.950797\n",
      "Name: 22, dtype: object\n",
      "31102/31102 [==============================] - 19s 608us/step\n",
      "6486/6486 [==============================] - 4s 609us/step\n",
      "7413/7413 [==============================] - 5s 609us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         4\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train              0.931335\n",
      "AUC Test 1             0.915528\n",
      "AUC Test 2             0.950316\n",
      "Name: 23, dtype: object\n",
      "31102/31102 [==============================] - 20s 628us/step\n",
      "6486/6486 [==============================] - 4s 632us/step\n",
      "7413/7413 [==============================] - 5s 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train               0.91963\n",
      "AUC Test 1             0.908709\n",
      "AUC Test 2             0.929143\n",
      "Name: 24, dtype: object\n",
      "31102/31102 [==============================] - 20s 627us/step\n",
      "6486/6486 [==============================] - 4s 623us/step\n",
      "7413/7413 [==============================] - 5s 627us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.905577\n",
      "AUC Test 1             0.897234\n",
      "AUC Test 2             0.912638\n",
      "Name: 25, dtype: object\n",
      "31102/31102 [==============================] - 19s 617us/step\n",
      "6486/6486 [==============================] - 4s 609us/step\n",
      "7413/7413 [==============================] - 5s 680us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train              0.933676\n",
      "AUC Test 1             0.918338\n",
      "AUC Test 2             0.951278\n",
      "Name: 26, dtype: object\n",
      "31102/31102 [==============================] - 20s 645us/step\n",
      "6486/6486 [==============================] - 4s 611us/step\n",
      "7413/7413 [==============================] - 5s 619us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        relu\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train              0.932104\n",
      "AUC Test 1             0.916521\n",
      "AUC Test 2             0.950572\n",
      "Name: 27, dtype: object\n",
      "31102/31102 [==============================] - 19s 615us/step\n",
      "6486/6486 [==============================] - 4s 616us/step\n",
      "7413/7413 [==============================] - 5s 646us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                  100\n",
      "AUC Train              0.932086\n",
      "AUC Test 1             0.915975\n",
      "AUC Test 2             0.950534\n",
      "Name: 28, dtype: object\n",
      "31102/31102 [==============================] - 20s 634us/step\n",
      "6486/6486 [==============================] - 4s 621us/step\n",
      "7413/7413 [==============================] - 5s 618us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     0.5\n",
      "Batch Size                10000\n",
      "AUC Train              0.930136\n",
      "AUC Test 1             0.913926\n",
      "AUC Test 2              0.94882\n",
      "Name: 29, dtype: object\n",
      "31102/31102 [==============================] - 20s 630us/step\n",
      "6486/6486 [==============================] - 4s 643us/step\n",
      "7413/7413 [==============================] - 5s 624us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                  100\n",
      "AUC Train              0.933439\n",
      "AUC Test 1             0.917751\n",
      "AUC Test 2             0.950986\n",
      "Name: 30, dtype: object\n",
      "31102/31102 [==============================] - 20s 652us/step\n",
      "6486/6486 [==============================] - 4s 628us/step\n",
      "7413/7413 [==============================] - 5s 610us/step\n",
      "# HL                          4\n",
      "#Node                         6\n",
      "Activation Function        tanh\n",
      "Dropout                     1.0\n",
      "Batch Size                10000\n",
      "AUC Train              0.931947\n",
      "AUC Test 1             0.916112\n",
      "AUC Test 2              0.95018\n",
      "Name: 31, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniqa\\AppData\\Local\\Temp\\ipykernel_13788\\3386485280.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters\n",
    "num_hidden_layers = [2, 4]\n",
    "num_nodes = [4, 6]\n",
    "activation_funcs = ['relu', 'tanh']\n",
    "dropout_rates = [0.5, 1.0]\n",
    "batch_sizes = [100, 10000]\n",
    "num_epochs = 20\n",
    "\n",
    "# create empty dataframe to store results\n",
    "results_df = pd.DataFrame(columns=['# HL', '#Node', 'Activation Function', 'Dropout', 'Batch Size', 'AUC Train', 'AUC Test 1', 'AUC Test 2'])\n",
    "\n",
    "# iterate through all combinations of hyperparameters\n",
    "for hl in num_hidden_layers:\n",
    "    for nn in num_nodes:\n",
    "        for af in activation_funcs:\n",
    "            for dr in dropout_rates:\n",
    "                for bs in batch_sizes:\n",
    "                    \n",
    "                    # build neural network model\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(nn, activation=af, input_shape=(X_train_normalized.shape[1],)))\n",
    "                    for i in range(hl - 1):\n",
    "                        model.add(Dense(nn, activation=af))\n",
    "                        if dr < 1.0:\n",
    "                            model.add(Dropout(dr))\n",
    "                    model.add(Dense(1, activation='sigmoid'))\n",
    "                    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "                    \n",
    "                    # train model\n",
    "                    model.fit(X_train_normalized, Y_train, batch_size=bs, epochs=num_epochs, verbose=0)\n",
    "                    \n",
    "                    # evaluate performance on train and test sets\n",
    "                    y_pred_train = model.predict(X_train_normalized).ravel()\n",
    "                    y_pred_test1 = model.predict(X_test1_normalized).ravel()\n",
    "                    y_pred_test2 = model.predict(X_test2_normalized).ravel()\n",
    "                    auc_train = roc_auc_score(Y_train, y_pred_train)\n",
    "                    auc_test1 = roc_auc_score(Y_test1, y_pred_test1)\n",
    "                    auc_test2 = roc_auc_score(Y_test2, y_pred_test2)\n",
    "                    \n",
    "                    # add results to dataframe\n",
    "                    results_df = results_df.append({'# HL': hl, '#Node': nn, 'Activation Function': af, 'Dropout': dr, 'Batch Size': bs, 'AUC Train': auc_train, 'AUC Test 1': auc_test1, 'AUC Test 2': auc_test2}, ignore_index=True)\n",
    "                    print(results_df.iloc[-1])\n",
    "                    # save results to csv after each iteration\n",
    "                    #results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(r\"C:\\Users\\aniqa\\Desktop\\Courses\\Semester_2\\Machine_Learning\\Project 1\\Code\\NN_grid_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2065a111110>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set best hyperparameters\n",
    "hl = 4\n",
    "nn = 4\n",
    "af = 'tanh'\n",
    "dr = 1.0\n",
    "bs = 100\n",
    "\n",
    "#fit the \n",
    "model = Sequential()\n",
    "model.add(Dense(nn, activation=af, input_shape=(X_train_normalized.shape[1],)))\n",
    "for i in range(hl - 1):\n",
    "    model.add(Dense(nn, activation=af))\n",
    "    if dr < 1.0:\n",
    "        model.add(Dropout(dr))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')              \n",
    "model.fit(X_train_normalized, Y_train, batch_size=bs, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31102/31102 [==============================] - 25s 795us/step\n",
      "6486/6486 [==============================] - 5s 785us/step\n",
      "7413/7413 [==============================] - 6s 829us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train_normalized).ravel()\n",
    "y_pred_test1 = model.predict(X_test1_normalized).ravel()\n",
    "y_pred_test2 = model.predict(X_test2_normalized).ravel()\n",
    "auc_train = roc_auc_score(Y_train, y_pred_train)\n",
    "auc_test1 = roc_auc_score(Y_test1, y_pred_test1)\n",
    "auc_test2 = roc_auc_score(Y_test2, y_pred_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
